name: Stock Analysis Pipeline

on:
  schedule:
    # Run every 30 minutes
    - cron: '*/30 * * * *'
    # Also run at market open and close (EST)
    - cron: '30 9 * * 1-5'   # 9:30 AM EST (market open)
    - cron: '0 16 * * 1-5'    # 4:00 PM EST (market close)
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  actions: write

concurrency:
  group: stock-analysis-pipeline
  cancel-in-progress: true

jobs:
  pipeline:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: ${{ secrets.DB_USER }}
          POSTGRES_PASSWORD: ${{ secrets.DB_PASSWORD }}
          POSTGRES_DB: ${{ secrets.DB_NAME }}
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Initialize database
        env:
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_HOST: localhost
          DB_PORT: 5432
        run: |
          python scripts/init_db.py

      - name: Seed stocks (if needed)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_HOST: localhost
          DB_PORT: 5432
        run: |
          python scripts/seed_stocks.py || echo "Stocks may already be seeded"
        continue-on-error: true

      - name: Run pipeline
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          DB_USER: ${{ secrets.DB_USER }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_NAME: ${{ secrets.DB_NAME }}
          DB_HOST: localhost
          DB_PORT: 5432
        run: |
          python scripts/run_pipeline.py 100  # Process 100 stocks per run

      - name: Upload exports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-exports
          path: exports/
          retention-days: 7
